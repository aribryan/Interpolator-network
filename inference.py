#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Author: Your Name <your@email.com>

import os
import argparse
import tensorflow as tf
import numpy as np
import cv2
from tensorpack import *
from networks import VGG,dumb_network1,U_net,vgg_ende,dumb_network2,some_func,Voxel3D
from SSIM_loss import SSIM

import cv2
from matplotlib import pyplot as plt


"""
This is a boiler-plate template.
All code is in this file is the most minimalistic way to solve a deep-learning problem with cross-validation.
"""

BATCH_SIZE = 16
SHAPE = 28
HEIGHT = 256
WIDTH = 256
CHANNELS = 3


def run_test(path, input1,input2):
    #param_dict = np.load(path, encoding='latin1').item()
    predict_func = OfflinePredictor(PredictConfig(
        inputs_desc=[InputDesc(tf.float32, (None, HEIGHT, WIDTH, 6), 'input')],
        tower_func=Voxel3D,
        session_init=SaverRestore(path),
        input_names=['input'],
        output_names=['Voxel_auto_encoder/conv11/output:0'
                      ]   # prob:0 is the probability distribution
    ))


    im1 = cv2.imread(input1)
    im2= cv2.imread(input2)
    #assert im is not None, input
    im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)
    #im1 = cv2.resize(im1, (HEIGHT,WIDTH)).reshape((1, HEIGHT, WIDTH, 3)).astype('float32')
    im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)
    #im2 = cv2.resize(im2, (HEIGHT, WIDTH)).reshape((1, HEIGHT, WIDTH, 3)).astype('float32')
    print(im2.shape)
    print('this size 1 here ')

    #im=concatenate(im1,im2)

    im1_small = cv2.resize(im1, (WIDTH, HEIGHT))[None, :, :, :]
    im2_small = cv2.resize(im2, (WIDTH, HEIGHT))[None, :, :, :]
    im = np.concatenate((im2_small, im1_small), axis=-1).astype('float32')
    # im = np.concatenate((im1_small,im2_small), axis=2).astype('float32')
    im_shape=im.shape
    print(im_shape)
    new_height=im_shape[0]
    new_width=im_shape[1]
    print('this size 2 here ')
    # im = cv2.resize(im, (WIDTH, HEIGHT)).reshape((1, HEIGHT, WIDTH, 6)).astype('float32')


    outputs = predict_func(im)

    image_out=np.asarray(outputs)

    print(image_out.shape)
    print("done")
    new=np.squeeze(image_out)
    new= 128.*(new + 1)
    new = np.clip(new, 0, 255).astype(np.uint8)
    #new = cv2.cvtColor(new, cv2.COLOR_RGB2BGR)
    print(new.shape)
    #plt.imshow(new)
    #plt.show()
    cv2.imwrite('middle_frame.png',new)
    # cv2.imwrite('viz.png', viz)
    cv2.imwrite('left_frame.png', im1)
    cv2.imwrite('input0.png', im1_small[0])
    cv2.imwrite('input2.png', im2_small[0])


    # print([n.name for n in predict_func.sess.graph.as_graph_def().node])


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--gpu', help='comma separated list of GPU(s) to use.')
    parser.add_argument('--load', required=True,
                        help='.npy model file generated by tensorpack.utils.loadcaffe')
    parser.add_argument('--input1', help='an input image', required=True)
    parser.add_argument('--input2', help='an input image', required=True)
    args = parser.parse_args()
    if args.gpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu
    run_test(args.load, args.input1,args.input2)
